{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQfyRWbnUxiYfjYokyjpW3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Manipulation\n","\n","\n","Data Manipulation is a fundamental skill in the field of data analysis and data science. It empowers you to transform raw data into meaningful insights, enabling informed decision-making and valuable discoveries.\n","\n","Lets explore various techniques for data manipulation using the Pandas library. We will use a house price dataset to demonstrate each section. Let's get started!\n","\n","## Section 1: Filtering Data\n","\n","\n","Filtering data is a basic but fundamental operation in data wrangling. As we've alredy seen it allows us to extract specific subsets of data that meet certain conditions or criteria incuding specific rows or columns.\n","\n","In this lesson, we will explore how to use the pandas library in Python to filter data efficiently. We will cover various filtering techniques and scenarios, from simple conditional filtering to more complex operations.\n","\n","\n","Lets start. To filter the data, we create a new DataFrame filtered_data by specifying a condition within square brackets []. In this example, we filter the dataset to include only the rows where the bedrooms column - BedroomAbvGr - has a value >= 6"],"metadata":{"id":"9kqsquRkIRGq"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"qV-p_iyKIM6a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713797482445,"user_tz":240,"elapsed":1352,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"d076393c-10aa-484c-a891-04033c3d96c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-04-22 14:51:21--  https://raw.githubusercontent.com/odsc2015/Data-Wrangling-With-SQL/main/kaggle-house-price-data-set.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 460676 (450K) [text/plain]\n","Saving to: ‘kaggle-house-price-data-set.csv’\n","\n","kaggle-house-price- 100%[===================>] 449.88K  --.-KB/s    in 0.1s    \n","\n","2024-04-22 14:51:22 (3.56 MB/s) - ‘kaggle-house-price-data-set.csv’ saved [460676/460676]\n","\n","Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n","       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n","       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n","       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n","       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n","       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n","       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n","       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n","       'HeatingQC', 'CentralAir', 'Electrical', 'FstFlrSF', 'SndFlrSF',\n","       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n","       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n","       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n","       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n","       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n","       'EnclosedPorch', 'TSsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n","       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n","       'SaleCondition', 'SalePrice'],\n","      dtype='object')\n","      Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n","144  145          90       RM         70.0     9100   Pave   NaN      Reg   \n","291  292         190       RL         55.0     5687   Pave  Grvl      Reg   \n","330  331          90       RL          NaN    10624   Pave   NaN      IR1   \n","570  571          90       RL         74.0    13101   Pave   NaN      IR1   \n","635  636         190       RH         60.0    10896   Pave  Pave      Reg   \n","\n","    LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal  \\\n","144         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n","291         Bnk    AllPub  ...        0    NaN   NaN         NaN       0   \n","330         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n","570         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n","635         Bnk    AllPub  ...        0    NaN   NaN         NaN       0   \n","\n","    MoSold YrSold  SaleType  SaleCondition  SalePrice  \n","144     11   2006     ConLI        Abnorml     125000  \n","291      3   2008        WD         Normal     135900  \n","330     11   2007        WD         Normal     119000  \n","570     11   2008        WD         Normal     142600  \n","635      3   2007        WD        Abnorml     200000  \n","\n","[5 rows x 81 columns]\n"]}],"source":["import pandas as pd\n","\n","# Get the house price dataset\n","!wget https://raw.githubusercontent.com/odsc2015/Data-Wrangling-With-SQL/main/kaggle-house-price-data-set.csv\n","\n","# Load the dataset\n","house_df = pd.read_csv('kaggle-house-price-data-set.csv')\n","\n","# Examining the Data\n","# Before we dive into filtering, let's familiarize ourselves with the dataset by printing the column names\n","print(house_df.columns)\n","\n","# Filtering data based on a condition\n","filtered_data = house_df[house_df['BedroomAbvGr'] >= 6]\n","\n","print(filtered_data.head())"]},{"cell_type":"markdown","source":[],"metadata":{"id":"YDLLAiEdcOF2"}},{"cell_type":"markdown","source":["\n","###  Filtering by a Single Condition\n","The most common form of filtering is based on a single condition. We can create a new DataFrame containing rows that meet this condition. In this example, we filter houses with six or more bedrooms.\n","\n","filtered_data = house_df[house_df['BedroomAbvGr'] >= 6]\n","\n","### Filtering with Multiple Conditions\n","You can also filter data based on multiple conditions by combining them using logical operators like & (and) and | (or). Here's an example that filters houses with both six or more bedrooms and three or more bathrooms.\n"],"metadata":{"id":"4ks38-oRLPxi"}},{"cell_type":"code","source":["# Filtering with multiple conditions (AND operator)\n","filtered_data = house_df[(house_df['BedroomAbvGr'] >= 3) & (house_df['FullBath'] >= 2)]\n","\n","# Display the first few rows of the filtered data\n","print(filtered_data.head())\n"],"metadata":{"id":"46CdB-uA7UlA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713797513519,"user_tz":240,"elapsed":319,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"9daeba59-cc7b-4814-bcc8-68fe97509a64"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n","0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n","1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n","2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n","4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n","6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n","\n","  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n","0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n","1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n","2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n","4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n","6         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      8   \n","\n","  YrSold  SaleType  SaleCondition  SalePrice  \n","0   2008        WD         Normal     208500  \n","1   2007        WD         Normal     181500  \n","2   2008        WD         Normal     223500  \n","4   2008        WD         Normal     250000  \n","6   2007        WD         Normal     307000  \n","\n","[5 rows x 81 columns]\n"]}]},{"cell_type":"markdown","source":["\n","## Sorting Data\n","\n","Sorting data is a fundamental data manipulation task that allows us to organize and analyze information efficiently.  Lets explore how to use the pandas library in Python to sort datasets based on one or more columns.\n","\n","Understanding sorting techniques is essential for tasks like identifying trends, finding the highest or lowest values, and preparing data for visualization or modeling.\n","\n","### Sorting by a Single Column\n","The simplest way to sort data is by a single column. We can use the\n","     \n","          sort_values()\n","      \n","method to do this. Here's an example of sorting houses by their price in ascending order which is the defaul. In the next lines we sort in descending order, you can use the ascending parameter and set it to False\n","\n"],"metadata":{"id":"oFYz3TuO7MLs"}},{"cell_type":"code","source":["# Sorting data based on a single column\n","\n","# Sort the data by the 'Price' column in ascending order\n","sorted_data = house_df.sort_values(by='SalePrice')\n","\n","# Display the sorted data\n","print(sorted_data.head())\n","\n","\n","# Sort the data by the 'SalePrice' column in descending order\n","sorted_data = house_df.sort_values('SalePrice', ascending=False)\n","\n","print(sorted_data.head())"],"metadata":{"id":"WqDiu6bzLUYu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713797545554,"user_tz":240,"elapsed":304,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"8aa3b576-5bb6-423c-8eb5-a6a459b9683d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["      Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n","495  496          30  C (all)         60.0     7879   Pave   NaN      Reg   \n","916  917          20  C (all)         50.0     9000   Pave   NaN      Reg   \n","968  969          50       RM         50.0     5925   Pave   NaN      Reg   \n","533  534          20       RL         50.0     5000   Pave   NaN      Reg   \n","30    31          70  C (all)         50.0     8500   Pave  Pave      Reg   \n","\n","    LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n","495         Lvl    AllPub  ...        0    NaN   GdWo         NaN       0   \n","916         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","968         Lvl    AllPub  ...        0    NaN   GdWo         NaN       0   \n","533         Low    AllPub  ...        0    NaN    NaN         NaN       0   \n","30          Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n","\n","    MoSold YrSold  SaleType  SaleCondition  SalePrice  \n","495     11   2009        WD        Abnorml      34900  \n","916     10   2006        WD        Abnorml      35311  \n","968      5   2009        WD        Abnorml      37900  \n","533      1   2007        WD         Normal      39300  \n","30       7   2008        WD         Normal      40000  \n","\n","[5 rows x 81 columns]\n","        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n","691    692          60       RL        104.0    21535   Pave   NaN      IR1   \n","1182  1183          60       RL        160.0    15623   Pave   NaN      IR1   \n","1169  1170          60       RL        118.0    35760   Pave   NaN      IR1   \n","898    899          20       RL        100.0    12919   Pave   NaN      IR1   \n","803    804          60       RL        107.0    13891   Pave   NaN      Reg   \n","\n","     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n","691          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","1182         Lvl    AllPub  ...      555     Ex  MnPrv         NaN       0   \n","1169         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","898          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","803          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","\n","     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n","691       1   2007        WD         Normal     755000  \n","1182      7   2007        WD        Abnorml     745000  \n","1169      7   2006        WD         Normal     625000  \n","898       3   2010       New        Partial     611657  \n","803       1   2009       New        Partial     582933  \n","\n","[5 rows x 81 columns]\n"]}]},{"cell_type":"markdown","source":["### Sorting by Multiple Columns\n","\n","You can also sort data by multiple columns, which can be helpful for complex sorting criteria. In this example, we'll sort by 'Bedrooms' in ascending order and then by 'Bathrooms' in descending order:"],"metadata":{"id":"sX5SmogW_9rp"}},{"cell_type":"code","source":["# Sort the data first by 'Bedrooms' in ascending order and then by 'Bathrooms' in descending order\n","multi_sorted_data = house_df.sort_values(by=['BedroomAbvGr', 'FullBath'], ascending=[True, False])\n","\n","# Display the sorted data\n","print(multi_sorted_data.head())"],"metadata":{"id":"9nXi72df_7_7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713797587392,"user_tz":240,"elapsed":418,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"29a9ab43-bab9-4634-8857-199c348ebcc8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n","189    190         120       RL         41.0     4923   Pave   NaN      Reg   \n","53      54          20       RL         68.0    50271   Pave   NaN      IR1   \n","634    635          90       RL         64.0     6979   Pave   NaN      Reg   \n","1163  1164          90       RL         60.0    12900   Pave   NaN      Reg   \n","1213  1214          80       RL          NaN    10246   Pave   NaN      IR1   \n","\n","     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n","189          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","53           Low    AllPub  ...        0    NaN    NaN         NaN       0   \n","634          Lvl    AllPub  ...        0    NaN  GdPrv        Shed     600   \n","1163         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","1213         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","\n","     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n","189       8   2008        WD         Normal     286000  \n","53       11   2006        WD         Normal     385000  \n","634       6   2010        WD         Normal     144000  \n","1163      1   2008        WD         Alloca     108959  \n","1213      5   2006        WD         Normal     145000  \n","\n","[5 rows x 81 columns]\n"]}]},{"cell_type":"markdown","source":["## Grouping Data\n","\n","Grouping data is a powerful technique in data analysis and data wrangling.\n","It allows us to aggregating and summarizing information based on specific criteria and also perform operations on groups of data. Again we can use  pandas to group and aggregate data effectively. Understanding grouping techniques is essential for tasks like summarizing statistics, exploring trends within subsets, and making data-driven decisions.\n","\n","### Grouping by a Single Column\n","One of the most common grouping tasks is aggregating data based on a single column. We can use the groupby() method for this.\n","\n","Here's an example of grouping houses by their neighborhood and calculating the mean sale price for each neighborhood:\n","\n","To group the data, we create a new Series grouped_data by calling the groupby() function on the DataFrame and specifying the column to group by ('Neighborhood'). We then select the 'SalePrice' column and apply the mean() function to calculate the mean price for each neighborhood"],"metadata":{"id":"79cU_UhZLr1o"}},{"cell_type":"code","source":["# Grouping data based on a column and calculating the mean\n","grouped_data = house_df.groupby('Neighborhood')['SalePrice'].mean()\n","\n","print(grouped_data)"],"metadata":{"id":"zJmXXPrfLxRJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713797710434,"user_tz":240,"elapsed":288,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"228e965d-c887-4128-92e5-be69835503b7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Neighborhood\n","Blmngtn    194870.882353\n","Blueste    137500.000000\n","BrDale     104493.750000\n","BrkSide    124834.051724\n","ClearCr    212565.428571\n","CollgCr    197965.773333\n","Crawfor    210624.725490\n","Edwards    128219.700000\n","Gilbert    192854.506329\n","IDOTRR     100123.783784\n","MeadowV     98576.470588\n","Mitchel    156270.122449\n","NAmes      145847.080000\n","NPkVill    142694.444444\n","NWAmes     189050.068493\n","NoRidge    335295.317073\n","NridgHt    316270.623377\n","OldTown    128225.300885\n","SWISU      142591.360000\n","Sawyer     136793.135135\n","SawyerW    186555.796610\n","Somerst    225379.837209\n","StoneBr    310499.000000\n","Timber     242247.447368\n","Veenker    238772.727273\n","Name: SalePrice, dtype: float64\n"]}]},{"cell_type":"markdown","source":["### Grouping by Multiple Columns\n","\n","You can also group data by multiple columns to create more complex groupings. For instance, you might want to group houses by both 'Neighborhood' and 'BldgType.' Here's an example:"],"metadata":{"id":"-RCT1MgeOc60"}},{"cell_type":"code","source":["# Group the data by both 'Neighborhood' and 'HouseType' and calculate the mean sale price for each combination\n","multi_grouped_data = house_df.groupby(['Neighborhood', 'BldgType'])['SalePrice'].mean()\n","\n","# Display the grouped data\n","print(multi_grouped_data)"],"metadata":{"id":"8NqQdZhCOkMg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713797722402,"user_tz":240,"elapsed":274,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"57e8676f-5936-454a-f48f-c3451596e429"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Neighborhood  BldgType\n","Blmngtn       1Fam        159895.000000\n","              TwnhsE      197056.875000\n","Blueste       Twnhs       151000.000000\n","              TwnhsE      124000.000000\n","BrDale        Twnhs       102408.333333\n","                              ...      \n","StoneBr       TwnhsE      220833.333333\n","Timber        1Fam        242606.837838\n","              2fmCon      228950.000000\n","Veenker       1Fam        223375.000000\n","              TwnhsE      279833.333333\n","Name: SalePrice, Length: 64, dtype: float64\n"]}]},{"cell_type":"markdown","source":["\n","## Combining Data\n","\n","Combining data involves merging or concatenating multiple datasets to create a unified view or to perform further analysis.\n","\n","Lets generate house data with two datasets;  dataset 1 and dataset 2 using dictionaries data_1 and data_2, respectively\n","\n","The first way to combine data is by vertically concatenating the DataFrames using\n","\n","      pd.concat()\n","\n","We pass a list of DataFrames [df1, df2] and set ignore_index=True to reindex the concatenated data.\n"],"metadata":{"id":"QNe5qDVgM92w"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Generate house data for dataset 1\n","data_1 = {\n","    'Address': ['123 Main St', '456 Elm St', '789 Oak St'],\n","    'Price': [500000, 600000, 450000],\n","    'Bedrooms': [3, 4, 2],\n","    'Bathrooms': [2, 2.5, 1.5]\n","}\n","\n","# Generate house data for dataset 2\n","data_2 = {\n","    'Address': ['321 Pine St', '654 Maple St'],\n","    'Price': [700000, 550000],\n","    'Bedrooms': [3, 3],\n","    'Bathrooms': [3, 2],\n","    'Garage': [2, 1]\n","}\n","\n","# Create DataFrames for each dataset\n","df1 = pd.DataFrame(data_1)\n","df2 = pd.DataFrame(data_2)\n","\n","# Concatenate DataFrames vertically\n","appended_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n","print('\\n', appended_df)\n"],"metadata":{"id":"6uCFjyfKNaXK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713797778393,"user_tz":240,"elapsed":342,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"727d8657-bd16-4d6b-f733-26320e4ec7e4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","         Address   Price  Bedrooms  Bathrooms  Garage\n","0   123 Main St  500000         3        2.0     NaN\n","1    456 Elm St  600000         4        2.5     NaN\n","2    789 Oak St  450000         2        1.5     NaN\n","3   321 Pine St  700000         3        3.0     2.0\n","4  654 Maple St  550000         3        2.0     1.0\n"]}]},{"cell_type":"markdown","source":["This is also known appending DataFrames vertically.\n","\n","In this code:\n","\n","* We use pd.concat() with the axis=0 parameter to indicate vertical concatenation (appending rows).\n","* The ignore_index=True parameter resets the index of the resulting DataFrame.\n","\n","\n","WWhen appending DataFrames vertically using methods like pd.concat(), there are a few rules and considerations to keep in mind:\n","\n","1. Column Names: The DataFrames should have the same column names. If the column names differ between the DataFrames, you may encounter issues during appending. If you want to keep columns that are only present in one of the DataFrames, you can set the ignore_index parameter to True, which will reset the index.\n","\n","2. Column Order: The order of columns should be the same in both DataFrames. If the column order differs, you may need to re-order the columns before appending.\n","\n","3. Index: By default, when appending, the index from each DataFrame is retained. If you want to create a new index or reset the index, you can use the ignore_index parameter and set it to True.\n","\n","4. Data Types: Column data types should be compatible. If there are differences in data types, pandas will attempt to cast the data to a common type. If a column cannot be cast, it may result in an error.\n","\n","5. Missing Data: If one of the DataFrames has missing data in certain columns, the appended DataFrame will have NaN values in those columns for rows where data is missing.\n","\n","6. Duplicates: If there are duplicate rows between the DataFrames, these duplicates will be retained in the appended DataFrame. If you want to remove duplicates, you can use the drop_duplicates() method after appending.\n","\n","Note that pandas also has the  \n","\n","    pd.append()\n","    \n","method which is similar to pd.concat(). It's an alternative to the pd.concat() function and provides a more concise way to combine two DataFrames. However, the rules and considerations for appending DataFrames using append() are quite similar to those for pd.concat():\n","\n","\n","### Merge\n","\n","We can also merge DataFrames horizontally in pandas. Merging horizontally typically involves combining DataFrames based on common columns (keys). The primary function for horizontal merging in pandas is\n","\n","      pd.merge().\n","\n","We specify the column to merge on using on='Address' and set how='inner' to perform an inner join.\n"],"metadata":{"id":"8vXRZPSMPCwo"}},{"cell_type":"code","source":["# Generate house data for dataset 1\n","data_1 = {\n","    'Address': ['123 Main St', '456 Elm St', '789 Oak St', '321 Pine St', '654 Maple St'],\n","    'Price': [500000, 600000, 450000,700000, 55000],\n","    'Bedrooms': [3, 4, 2,3, 3],\n","    'Bathrooms': [2, 2.5, 1.5,3,2]\n","}\n","\n","# Generate house data for dataset 2\n","data_2 = {\n","     'Address': ['123 Main St', '456 Elm St', '789 Oak St', '321 Pine St', '654 Maple St'],\n","     'Garage': [2, 1,0,2,1],\n","     'BldgType': ['1Fam','TwnhsE','2fmCon','1Fam', '1Fam']\n","}\n","\n","# Create DataFrames for each dataset\n","df1 = pd.DataFrame(data_1)\n","df2 = pd.DataFrame(data_2)\n","\n","\n","print('\\n', data_1)\n","print('\\n', data_2)\n","\n","# Merge DataFrames based on a common column\n","merged_data = pd.merge(df1, df2, on='Address', how='inner')\n","\n","print(\"\\nMerged Data:\")\n","print(merged_data)\n"],"metadata":{"id":"BVVWfov2PMR-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713797911020,"user_tz":240,"elapsed":454,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"aabd5d4e-5f58-467f-e3bc-95d68a89603b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," {'Address': ['123 Main St', '456 Elm St', '789 Oak St', '321 Pine St', '654 Maple St'], 'Price': [500000, 600000, 450000, 700000, 55000], 'Bedrooms': [3, 4, 2, 3, 3], 'Bathrooms': [2, 2.5, 1.5, 3, 2]}\n","\n"," {'Address': ['123 Main St', '456 Elm St', '789 Oak St', '321 Pine St', '654 Maple St'], 'Garage': [2, 1, 0, 2, 1], 'BldgType': ['1Fam', 'TwnhsE', '2fmCon', '1Fam', '1Fam']}\n","\n","Merged Data:\n","        Address   Price  Bedrooms  Bathrooms  Garage BldgType\n","0   123 Main St  500000         3        2.0       2     1Fam\n","1    456 Elm St  600000         4        2.5       1   TwnhsE\n","2    789 Oak St  450000         2        1.5       0   2fmCon\n","3   321 Pine St  700000         3        3.0       2     1Fam\n","4  654 Maple St   55000         3        2.0       1     1Fam\n"]}]},{"cell_type":"markdown","source":["## Results Review\n","\n","We merged two DataFrames with a common column 'key', in this case 'address'\n","\n","    merged_data = pd.merge(df1, df2, on='Address', how='inner')\n","\n","* pd.merge() is used to merge these DataFrames horizontally based on the 'key' column.\n","* The on parameter specifies the common column to merge on.\n","* The how parameter determines the type of merge (e.g., 'inner', 'outer', 'left', 'right').\n","\n","Here's a brief explanation of common merge types:\n","\n","* 'inner': Retains only rows with matching keys in both DataFrames (intersection).\n","* 'outer': Retains all rows from both DataFrames, filling missing values with NaN (union).\n","* 'left': Retains all rows from the left DataFrame and matching rows from the right DataFrame.\n","* 'right': Retains all rows from the right DataFrame and matching rows from the left DataFrame.\n","\n","You may recall from our Data Wrangling with SQL course. Thus you can see how, similar to SQL, horizontal merging is useful when you want to combine datasets with shared columns or keys. It allows you to bring related information from different DataFrames into a single, merged DataFrame."],"metadata":{"id":"i5NGWDiwXtnO"}},{"cell_type":"markdown","source":["# Exercises\n","\n","## Exercise 1: Filtering Data\n","\n","Filter the house dataset to display houses with more than 3 bedrooms. You can start with the following code\n","\n","    import pandas as pd\n","\n","    # Get the house price dataset\n","    !wget https://raw.githubusercontent.com/odsc2015/Data-Wrangling-With-SQL/main/kaggle-house-price-data-set.csv\n","\n","    # Load the dataset\n","    house_df = pd.read_csv('kaggle-house-price-data-set.csv')\n"],"metadata":{"id":"fnR1nlXnbEf7"}},{"cell_type":"markdown","source":["## Exercise 2: Grouping Data\n","\n","Group the house dataset by 'Neighborhood' and calculate the mean sale price for each neighborhood.\n","\n","## Exercise 3: Appending Data\n","\n","Create two DataFrames, df1 and df2, with the same column names ('A' and 'B') with the following data and append df2 below df1.\n","\n","    df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n","    df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n","\n","\n"],"metadata":{"id":"dQV3TPfkcP-C"}}]}