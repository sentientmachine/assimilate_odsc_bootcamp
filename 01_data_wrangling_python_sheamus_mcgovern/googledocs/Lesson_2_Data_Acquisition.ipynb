{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1TA5tx3vSTfUlXSzTaY7bdaQHE6w3lLdf","timestamp":1688345226245}],"authorship_tag":"ABX9TyNVkLJTMeEJuFzRskUzpmMK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Reading Files into Dataframes\n"," Let's dive into how to use Pandas to load CSV files and perform basic operations on the data.\n","\n","We start by importing the Pandas library using the import pandas as pd statement.\n","\n","To load a CSV file into a DataFrame, we use the pd.read_csv() function and pass the path to the CSV file as the argument. Replace 'path/to/your/file.csv' with the actual file path.\n","\n","If you are using **colab** then\n","\n","1. Click on the Files icon in the left sidebar to use the Using the Files explorer\n","2. Click on the Upload button. Select the local file from your local machine and click Open\n","3. Copy the file path and place in pd.read_csv\n","\n","NOTE: by default, CoLab loads the file to you **content** directory\n","\n","After loading the data, we can display the first few rows of the DataFrame using the df.head() method. This provides a quick overview of the data structure and column names."],"metadata":{"id":"F5o3pcCAKxHi"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load a CSV file into a DataFrame\n","\n","# set the path to your path and file name ie. 'path/to/your/file.csv'\n","\n","csv_file = '/content/kaggle-house-price-data-set.csv'\n","\n","!pwd\n","\n","#csv_file = '/content/sample_data/california_housing_test.csv'\n","\n","df = pd.read_csv(csv_file)\n","\n","# Display the first few rows of the DataFrame\n","print(df.head())\n"],"metadata":{"id":"aVzC2J5PK5Kk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## WGET\n","\n","A lot of data can be sourced online. Lets use a function to pull a data file directly from the web.\n","\n","To retrieve the dataset lets use **wget** which is a It is a popular tool for downloading files and does not require any additional libraries to be loaded or installed. Recall we use this file in our data wrangling course so lets get the raw file from the github repository."],"metadata":{"id":"vQdpxl2D8tLX"}},{"cell_type":"code","source":["# WGET with HTTPS file path\n","\n","# !wget https://raw.githubusercontent.com/odsc2015/Data-Wrangling-With-SQL/main/kaggle-house-price-data-set.csv\n","\n","# Reanme the retrieved file using -O parameter\n","!wget -O second_house_price_set.csv  https://raw.githubusercontent.com/odsc2015/Data-Wrangling-With-SQL/main/kaggle-house-price-data-set.csv\n","\n","# Load the dataset\n","house_df = pd.read_csv('second_house_price_set.csv')\n","\n","house_df.columns\n"],"metadata":{"id":"UVqaY0xN8r7Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713795126092,"user_tz":240,"elapsed":312,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"5af48eed-e452-4583-ee93-e95a0bcce1ff"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-04-22 14:12:05--  https://raw.githubusercontent.com/odsc2015/Data-Wrangling-With-SQL/main/kaggle-house-price-data-set.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 460676 (450K) [text/plain]\n","Saving to: ‘second_house_price_set.csv’\n","\n","\r          second_ho   0%[                    ]       0  --.-KB/s               \rsecond_house_price_ 100%[===================>] 449.88K  --.-KB/s    in 0.04s   \n","\n","2024-04-22 14:12:05 (12.1 MB/s) - ‘second_house_price_set.csv’ saved [460676/460676]\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n","       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n","       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n","       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n","       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n","       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n","       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n","       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n","       'HeatingQC', 'CentralAir', 'Electrical', 'FstFlrSF', 'SndFlrSF',\n","       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n","       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n","       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n","       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n","       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n","       'EnclosedPorch', 'TSsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n","       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n","       'SaleCondition', 'SalePrice'],\n","      dtype='object')"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## Describe Our File\n","\n","\n","Recall We can use the df.describe() method to get summary statistics of the data, such as count, mean, standard deviation, minimum, and maximum values for numeric columns.\n","\n","Accessing specific columns is straightforward.  \n","\n","We can filter the data based on conditions using boolean indexing. In the example, df['Column_Name'] > 100 filters the DataFrame to include only rows where the values in the 'Column_Name' column are greater than 100. The filtered data is stored in the filtered_data variable.\n","\n","Finally, Pandas provides a wide range of functionalities for data manipulation and analysis, allowing you to perform various operations like data transformations, aggregations, merging datasets, and more."],"metadata":{"id":"LMMxskPaLIHw"}},{"cell_type":"code","source":["\n","# Get summary statistics of the data\n","print(house_df.describe(include='all'))\n","\n","# Access specific columns\n","print(house_df['SalePrice'])\n","\n","# Filter data based on conditions\n","filtered_data = house_df[house_df['SalePrice'] > 100000]"],"metadata":{"id":"23qrgFHcLWID","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713795151379,"user_tz":240,"elapsed":336,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"9e34076b-835e-4075-c1af-5f6be3ce8f67"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["                 Id   MSSubClass MSZoning  LotFrontage        LotArea Street  \\\n","count   1460.000000  1460.000000     1460  1201.000000    1460.000000   1460   \n","unique          NaN          NaN        5          NaN            NaN      2   \n","top             NaN          NaN       RL          NaN            NaN   Pave   \n","freq            NaN          NaN     1151          NaN            NaN   1454   \n","mean     730.500000    56.897260      NaN    70.049958   10516.828082    NaN   \n","std      421.610009    42.300571      NaN    24.284752    9981.264932    NaN   \n","min        1.000000    20.000000      NaN    21.000000    1300.000000    NaN   \n","25%      365.750000    20.000000      NaN    59.000000    7553.500000    NaN   \n","50%      730.500000    50.000000      NaN    69.000000    9478.500000    NaN   \n","75%     1095.250000    70.000000      NaN    80.000000   11601.500000    NaN   \n","max     1460.000000   190.000000      NaN   313.000000  215245.000000    NaN   \n","\n","       Alley LotShape LandContour Utilities  ...     PoolArea PoolQC  Fence  \\\n","count     91     1460        1460      1460  ...  1460.000000      7    281   \n","unique     2        4           4         2  ...          NaN      3      4   \n","top     Grvl      Reg         Lvl    AllPub  ...          NaN     Gd  MnPrv   \n","freq      50      925        1311      1459  ...          NaN      3    157   \n","mean     NaN      NaN         NaN       NaN  ...     2.758904    NaN    NaN   \n","std      NaN      NaN         NaN       NaN  ...    40.177307    NaN    NaN   \n","min      NaN      NaN         NaN       NaN  ...     0.000000    NaN    NaN   \n","25%      NaN      NaN         NaN       NaN  ...     0.000000    NaN    NaN   \n","50%      NaN      NaN         NaN       NaN  ...     0.000000    NaN    NaN   \n","75%      NaN      NaN         NaN       NaN  ...     0.000000    NaN    NaN   \n","max      NaN      NaN         NaN       NaN  ...   738.000000    NaN    NaN   \n","\n","       MiscFeature       MiscVal       MoSold       YrSold  SaleType  \\\n","count           54   1460.000000  1460.000000  1460.000000      1460   \n","unique           4           NaN          NaN          NaN         9   \n","top           Shed           NaN          NaN          NaN        WD   \n","freq            49           NaN          NaN          NaN      1267   \n","mean           NaN     43.489041     6.321918  2007.815753       NaN   \n","std            NaN    496.123024     2.703626     1.328095       NaN   \n","min            NaN      0.000000     1.000000  2006.000000       NaN   \n","25%            NaN      0.000000     5.000000  2007.000000       NaN   \n","50%            NaN      0.000000     6.000000  2008.000000       NaN   \n","75%            NaN      0.000000     8.000000  2009.000000       NaN   \n","max            NaN  15500.000000    12.000000  2010.000000       NaN   \n","\n","        SaleCondition      SalePrice  \n","count            1460    1460.000000  \n","unique              6            NaN  \n","top            Normal            NaN  \n","freq             1198            NaN  \n","mean              NaN  180921.195890  \n","std               NaN   79442.502883  \n","min               NaN   34900.000000  \n","25%               NaN  129975.000000  \n","50%               NaN  163000.000000  \n","75%               NaN  214000.000000  \n","max               NaN  755000.000000  \n","\n","[11 rows x 81 columns]\n","0       208500\n","1       181500\n","2       223500\n","3       140000\n","4       250000\n","         ...  \n","1455    175000\n","1456    210000\n","1457    266500\n","1458    142125\n","1459    147500\n","Name: SalePrice, Length: 1460, dtype: int64\n"]}]},{"cell_type":"markdown","source":["## Web Scraping\n","\n","Lets demonstrate the basic process of web scraping using the BeautifulSoup library.\n","\n","We start by sending a GET request to the website of interest using the requests.get() function. In this example, we scrape data from 'https://www.example.com', but you can replace it with the URL of the website you want to scrape.\n","\n","Next, we create a BeautifulSoup object by passing the response content (response.content) and the parser to use (in this case, 'html.parser'). The BeautifulSoup library parses the HTML content and provides methods for extracting specific data.\n","\n","We use the find() method of the BeautifulSoup object to locate specific HTML elements. In this example, we extract the text within the first <h1> tag using soup.find('h1').text. We also extract all paragraphs (<p> tags) on the page using soup.find_all('p').\n","\n","Finally, we print the extracted data to the console."],"metadata":{"id":"sRiNIFPN-3RR"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","# Send a GET request to the website\n","url = 'https://www.example.com'\n","response = requests.get(url)\n","\n","# Create a BeautifulSoup object to parse the HTML content\n","soup = BeautifulSoup(response.content, 'html.parser')\n","\n","# Extract data from specific elements\n","title = soup.find('h1').text\n","paragraphs = soup.find_all('p')\n","\n","# Print the extracted data\n","print(\"Title:\", title)\n","print(\"Paragraphs:\")\n","for p in paragraphs:\n","    print(p.text)"],"metadata":{"id":"uN7jUPoT-4ln","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713795219884,"user_tz":240,"elapsed":581,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"480ce5e1-0888-4491-e271-daae67cc5bcc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Title: Example Domain\n","Paragraphs:\n","This domain is for use in illustrative examples in documents. You may use this\n","    domain in literature without prior coordination or asking for permission.\n","More information...\n"]}]},{"cell_type":"markdown","source":["Lets try something more interesting. Lets scrape Apple's stock price from Google Finance using BeautifulSoup, you'll need to perform several steps:\n","\n","1. Send an HTTP request to Google Finance's Apple stock page.\n","2. Parse the HTML content of the page using BeautifulSoup.\n","3. Locate and extract the relevant stock price information from the parsed HTML."],"metadata":{"id":"OJweywbFS-os"}},{"cell_type":"markdown","source":["\n","\n"],"metadata":{"id":"zY3OfqPOSkc9"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","# Send an HTTP GET request to the Google Finance page for Apple's stock\n","url = \"https://www.google.com/finance/quote/AAPL:NASDAQ\"\n","response = requests.get(url)\n","\n","# Check if the request was successful (status code 200)\n","if response.status_code == 200:\n","    # Parse the HTML content of the page\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","\n","    # Find the element containing the stock price\n","    price_element = soup.find(\"div\", class_=\"YMlKec fxKbKc\")\n","\n","    if price_element:\n","        # Extract and print the stock price\n","        stock_price = price_element.text.strip()\n","        print(f\"Apple's stock price: {stock_price}\")\n","    else:\n","        print(\"Stock price element not found on the page.\")\n","else:\n","    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"],"metadata":{"id":"a4BlDwSdR89D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713795372748,"user_tz":240,"elapsed":700,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"3a8b4747-a272-483a-b268-9f1561ad3b2d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Apple's stock price: $399.82\n"]}]},{"cell_type":"markdown","source":["## Code Review.\n","\n","Heres's how we got the stock price\n","\n","1. We import two libraries: requests for making HTTP requests to the website, and BeautifulSoup for parsing HTML content.\n","2. We define the URL of Apple's stock page on Google Finance and send an HTTP GET request to that URL using the requests.get() function. The response is stored in the response variable.\n","3. We check if the HTTP request was successful by verifying that the status code is 200, which indicates a successful response.\n","4. We create a BeautifulSoup object (soup) by parsing the HTML content of the page. The response.text contains the HTML content, and 'html.parser' is the parser used to parse the HTML.\n","5. We use BeautifulSoup's find() method to locate the HTML element that contains the stock price. In this case, we search for a <div> element with the class \"YMlKec fxKbKc\". Please note that this class selector may change over time, and it's essential to inspect the page's source code to find the correct selector.\n","5. If the price_element is found (i.e., not None), we extract the text within the element using price_element.text and remove any leading or trailing whitespace with strip(). Then, we print the stock price.\n","If the price_element is not found, we print a message indicating that the stock price element was not found on the page.\n","\n","Try MSFT stock price yourself\n","\n","\n","REMEMBER - Please respect the privacy and copywrite requirements of any website you scrape!\n","\n","## APIs\n","\n","API stands for Application Programming Interface. It's a set of rules and protocols that allows different software applications to communicate with each other. APIs are used to request and exchange data between systems, making it possible for your application to interact with external services, retrieve data, and perform various tasks.\n","\n","## API in Action\n","We can use an API to retrieve data from on onlive data provider using the  requests library in Python.\n","\n","We start by sending a GET request to the API endpoint of interest using the requests.get() function. Replace 'https://api.example.com/data' with the actual API endpoint URL.\n","\n","We check the status code of the response using response.status_code. A status code of 200 indicates a successful request.\n","\n","If the request is successful, we extract the data from the response using response.json(). This converts the response content (usually in JSON format) into a Python object that we can work with.\n","\n","Once we have the data, we can process and analyze it further based on our specific requirements.\n","\n"],"metadata":{"id":"2_gXO-0PAUHT"}},{"cell_type":"code","source":["import requests\n","\n","# Send a GET request to the API\n","url = \"https://jsonplaceholder.typicode.com/users/2\"  # Random API that doesnt' require and API 'KEY'\n","response = requests.get(url)\n","\n","# Check the status code\n","if response.status_code == 200:\n","    # Extract data from the response\n","    data = response.json()\n","    print(data)\n","\n","    # Process and analyze the data\n","    # ...\n","else:\n","    print(\"Error:\", response.status_code)"],"metadata":{"id":"Nx_I3X_SAUm9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713795509237,"user_tz":240,"elapsed":263,"user":{"displayName":"Sheamus McGovern","userId":"13415996168155356894"}},"outputId":"624206f6-9aa4-431a-97de-95c1717b363c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["{'id': 2, 'name': 'Ervin Howell', 'username': 'Antonette', 'email': 'Shanna@melissa.tv', 'address': {'street': 'Victor Plains', 'suite': 'Suite 879', 'city': 'Wisokyburgh', 'zipcode': '90566-7771', 'geo': {'lat': '-43.9509', 'lng': '-34.4618'}}, 'phone': '010-692-6593 x09125', 'website': 'anastasia.net', 'company': {'name': 'Deckow-Crist', 'catchPhrase': 'Proactive didactic contingency', 'bs': 'synergize scalable supply-chains'}}\n"]}]},{"cell_type":"markdown","source":["# Exercises\n","\n","## Exercise 1\n","\n","Using WGET retrieve the following file from github and examine it contents\n","\n","https://raw.githubusercontent.com/odsc2015/Data-Wrangling-With-SQL/main/new_customers_attempt_a.csv\n","\n","## Exercise 2\n","\n","Using the requests and BeautifulSoup libraries get the stock price for another NASDAQ exchange stock such as NVDA which has the ticker for NVIDIA\n"],"metadata":{"id":"UmtjFHW2W1RZ"}}]}