# assimilate_odsc_bootcamp

3 Goals:

1. Reverse Engineer the brain using odsc gain of compute functions.
2. Find someone who can implement LLVM's and ChatGPT and buy them coffee.
3. Get a job doing pure research and demos for replicating whatever ChatGPT is doing in modified domains.  

# Class list, clicky

## Day 1

[class01_data_wrangling_with_python_with_Sheamus_McGovern.md](./class01_data_wrangling_with_python_with_Sheamus_McGovern.md)

[class02_introduction_to_math_for_data_science_by_thomas_nield.md](./class02_introduction_to_math_for_data_science_by_thomas_nield.md)

[class03_practical_introduction_data_viz_for_data_scientists_robert_kosara.md](./class03_practical_introduction_data_viz_for_data_scientists_robert_kosara.md)

[class04_introduction_machine_learning_python_Sudip_Shrestha.md](./class04_introduction_machine_learning_python_Sudip_Shrestha.md)

# Day 2

state of the art open source AI with Hugging face

[class05_state_of_the_art_open_source_ai_hugging_face_julien_simon.md](./class05_state_of_the_art_open_source_ai_hugging_face_julien_simon.md)


Get rebuff API key, get usage hook to chat.openai.com.
[class06_api_for_gpt_andras_zsom.md](./class06_api_for_gpt_andras_zsom.md)

[class07_data_science_biotech_reearch_pharma_eric_ma_phd.md](./class07_data_science_biotech_reearch_pharma_eric_ma_phd.md)

Dive into the lightning ai open source stack and lightning studios to unlock reproducible ai development on the cloud by Luca Antiga.  Lightning AI, CTO.  https://www.linkedin.com/in/lantiga/  Pytorch llightning leading open source framework.


LLM-native products: industry best practices and what's ahead .  By Ivan Lee Datasour.ai CEO/Founder
The next generation of llm powered productions.
vip platinum gold silver bootcamp.


!!!
Assimilate all this: https://www.kaggle.com/code  trending


Pipe his IPYNB's into google colab and reproduce his work
[class08_ben_needs_a_friend_llvm_benjamin_batorsky.md](./class08_ben_needs_a_friend_llvm_benjamin_batorsky.md)



Good: (flatten to class09)
Machine Learning: Jon k Rohn's https://www.linkedin.com/in/jonkrohn
At Nebula:
https://www.linkedin.com/company/nebula-io
Generative A.I. with Open-Source LLMs: From Training to Deployment with Hugging Face and PyTorch Lightning
Parts of this training will be accessible to anyone who would like to understand how to develop commercially-successful data products in the new paradigm unleashed by LLMs like GPT-4. To make the most of this training, attendees should be proficient in deep learning and Python programming. Jon Krohn's "Deep Learning with PyTorch and TensorFlow" training on April 23rd provides the neural-network foundations for this generative A.I. training.
Tools/Languages utilized: Google Colab and Paperspace, Python
Code can be found in the aptly named code directory (
https://github.com/jonkrohn/NLP-with-LLMs/tree/main/code
Jupyter Notebooks are directly supported for execution in Google Colab
https://colab.research.google.com/
.py files are for running at the command line (see instructions)
N.B.: Code is intended to be accompanied by live instructions and so it will not necessarily be self-explanatory.
https://github.com/jonkrohn/NLP-with-LLMs
https://github.com/jonkrohn/DLTFpT/blob/master/notebooks/softmax_demo.ipynb




Idiomatic Pandas 2pm to 3pm  with matt harrison metasnake.  python and data science corporate trainer consultant.  ODSC East 2024 Prerequisites 100% Prerequisites to download:
1. Install pandas on your machine (using Anaconda or pip).
2. Install Jupyter on your machine.
3. Launch Jupyter and run the following: https://github.com/mattharrison/effective_pandas_book/blob/main/02-install-code.ipynb  
Github: https://github.com/mattharrison/effective_pandas_book
Prerequisites to download:
1. Install pandas on your machine (using Anaconda or pip).
2. Install Jupyter on your machine.
3. Launch Jupyter and run the following: https://github.com/mattharrison/effective_pandas_book/blob/main/02-install-code.ipynb
Github: https://github.com/mattharrison/effective_pandas_book

[class10_using_graphs_for_large_feature_engineering_pipelines_wes_madrigal.md](./class10_using_graphs_for_large_feature_engineering_pipelines_wes_madrigal.md)





How to Practice Data-Centric AI and Have AI Improve its Own Dataset (DE Summit) with Jonas Mueller , Chief Scientist and Co-Founder | Cleanlab 
In Machine Learning projects, one starts by exploring the data and training an initial baseline model. While it’s tempting to experiment with different modeling techniques right after that, an emerging science of data-centric AI introduces systematic techniques to utilize the baseline model to find and fix dataset issues. Improving the dataset in this manner, one can drastically improve the initial model’s performance without any change to the modeling code at all! These techniques work with any ML model and the improved dataset can be used to train any type of model (allowing modeling improvements to be stacked on top of dataset improvements). Such automated data curation has been instrumental to the success of AI organizations like OpenAI and Tesla.  
While data scientists have long been improving data through manual labor, data-centric AI studies algorithms to do this automatically. This tutorial will teach you how to operationalize fundamental ideas from data-centric AI across a wide variety of datasets (image, text, tabular, etc). We will cover recent algorithms to automatically identify common issues in real-world data (label errors, bad data annotators, outliers, low-quality examples, and other dataset problems that once identified can be easily addressed to significantly improve trained models). Open-source code to easily run these algorithms within end-to-end Data Science projects will also be demonstrated. After this tutorial, you will know how to use models to improve your data, in order to immediately retrain better models (and iterate this data/model improvement in a virtuous cycle).


### Linear Algebra with John K Rohn is good

* get Assimilate

https://github.com/jonkrohn/DLTFpT/blob/master/notebooks/deep_net_in_pytorch.ipynb

website:
https://www.jonkrohn.com/resources


Programming: All code demos will be in Python so experience with it or another object-oriented programming language would be helpful for following along with the code examples.

Mathematics: Familiarity with secondary school-level mathematics will make the class easier to follow along with. If you are comfortable dealing with quantitative information -- such as understanding charts and rearranging simple equations -- then you should be well-prepared to follow along with all of the mathematics.

Github repository for the original Notebook  https://github.com/jonkrohn/ML-foundations/tree/master/notebooks
Linear Algebra Colab 1  https://colab.research.google.com/github/jonkrohn/ML-foundations/blob/master/notebooks/1-intro-to-linear-algebra.ipynb
Linear Algebra Colab 2 https://colab.research.google.com/github/jonkrohn/ML-foundations/blob/master/notebooks/2-linear-algebra-ii.ipynb

Google Drive to Files  https://drive.google.com/drive/folders/1HPiLTf4u-hXJd7ISTHrI28IBls8n4UxG?usp=sharing

Jupyter Notebooks Guide
 https://docs.google.com/document/d/1vpASB2kjn_XUGTJNwknhIEDWfK8cMhq7v8vyoggmw5M/edit#heading=h.wp9t8n7j3og


### Data Cleaning

Eric Callahan , Principal, Data Solutions | Pickaxe Foundry
https://www.linkedin.com/in/ericcallahan

Cross Entopy loss.  Calculate loss between two bell distributions of priors and models given.
https://en.wikipedia.org/wiki/Cross-entropy


Clean as You Go: Basic Hygiene in the Modern Data Stack (DE Summit)


When my children walk around the house, they generally leave a trail of mess behind them. They sometimes realize that they shouldn't be doing this, but they’re so excited to move on to the next thing that catches their eye that they’ll say “Oh, I’ll clean it up later.”

As grown adults with wisdom gained from experience, my wife and I know that this means either:

They’ve just signed themselves up for a massive future cleaning job, or … … that someone else will have to clean up after them.

We know that this is not good behavior for a child, so why do we so often do this as Data Engineers?

The culture of “Move Fast and Break Things” has pressured us into closing tickets as quickly as possible, frequently pushing us towards the “Oh, I’ll clean it up later” mindset. While this may save us a few minutes in the short-term, we are creating long term headaches such as:

Piles of small cleanup tasks for later Confusion among peers who try to use incomplete data assets Lack of metadata to activate throughout the Modern Data Stack


### Unlock safety and savings mastering a secure cost effective cloud data lake

Ori Nakar Imperva Principal engineer threat research

Jonathan azaria imperva data science tech lead.



# Day 3

Trust, Transparency and secured generative AI
9:00AM to 9:25AM
Ballroom B
Kate Soule IBM program director generative AI research
https://www.linkedin.com/in/katesoule
1 person startup: "IBM": https://www.linkedin.com/company/ibm/
Jon Krohn will give an LLVM class from 11AM to 4PM.

Learning from mistakes: Empowering Humans to use AI the right way in high stakes decision making
9:30AM to 9:55AM
Ballroom B
Hilke Schellmann author of "The algorithm" assistant professor of journalism, new york university
https://www.linkedin.com/in/hilkeschellmann
Hachette Book Group: https://www.linkedin.com/company/hachette-book-group


How to Scale Trustworthy AI
10:00AM to 10:30AM
Ballroom B
Paul Hake Principal AI Engineer, IBM
https://www.linkedin.com/in/paul-hake


From Code to Trust Embedding Trustworthy proactices across the AI Lifecycle
10:00AM to 10:30
Ballroom A
Vrushali Sawant SAS Data Scientist Data Ethics Practice
https://www.linkedin.com/in/vrushalipsawant/


Choose:
Book Author: Quick Start Guide to large language Models
10:30AM to 11:00AM
Expo Hall Networking Area
Sinan Ozdemir LoopGenius, AI and LLM Expert Author and cofounder CTO
https://www.linkedin.com/in/sinan-ozdemir


Who wants to live forever?  Reliability engineering and mortality.
11AM to 11:30
Allen Downey Phd Brilliant.org
https://www.linkedin.com/in/allendowney
Ballroom B


Choose:
Generative AI with opensource llms from training to deployment Hugging face and pytorch lightning.
Dr Jon Krohn.
11:00AM to 4PM
https://www.linkedin.com/in/jonkrohn/
Room 312
[class11_generative_ai_opensource_llms_hugging_face_pytorch_jon_krohn.md](./class11_generative_ai_opensource_llms_hugging_face_pytorch_jon_krohn.md)



Developing Credit Scoring Models for banking and Beyond
Room 304
11AM to 1PM
Aric Labarr PHD Institute for Advanced Analytics at NC state university


LLMs Meet Google cloud.  A new frontier in big data analytics.
11AM to 1PM
Room 302
Mohammad Soltanieh-ha
Rohan Johar


WOW!  20 years Quant Bloomberg.
Imputation of financial data using collaborative filtering and generative machine learning
Ballroom A
11:00AM to 11:30
Arun Verma PhD bloomberg, head of quant research.
https://www.linkedin.com/in/arun-verma-0858b8/

Applied to bloomberg job application steps lol.


VIRTUAL1:
Build GenAI Systems, Not Models,, 
Hugo Bowne-Anderson , Head of Developer Relations | Outerbounds
10AM to 10:30
This talk explores a framework for how data scientists can deliver value with Generative AI: How can you embed LLMs and foundation models into your pre-existing software stack? How can you do so using Open Source Python? What changes about the production machine learning stack and what remains the same?
We motivate the concepts through generative AI examples in domains such as text-to-image (Stable Diffusion) and text-to-speech (Whisper) applications. Moreover, we’ll demonstrate how workflow orchestration provides a common scaffolding to ensure that your Generative AI and classical Machine Learning workflows alike are robust and ready to move safely into production systems.
This talk is aimed squarely at (data) scientists and ML engineers who want to focus on the science, data, and modeling, but want to be able to access all their infrastructural, platform, and software needs with ease!


VIRTUAL2:
Build GenAI Systems, Not Models 
Hugo Bowne-Anderson , Head of Developer Relations | Outerbounds
This talk explores a framework for how data scientists can deliver value with Generative AI: How can you embed LLMs and foundation models into your pre-existing software stack? How can you do so using Open Source Python? What changes about the production machine learning stack and what remains the same?
We motivate the concepts through generative AI examples in domains such as text-to-image (Stable Diffusion) and text-to-speech (Whisper) applications. Moreover, we’ll demonstrate how workflow orchestration provides a common scaffolding to ensure that your Generative AI and classical Machine Learning workflows alike are robust and ready to move safely into production systems.
This talk is aimed squarely at (data) scientists and ML engineers who want to focus on the science, data, and modeling, but want to be able to access all their infrastructural, platform, and software needs with ease!


VIRTUAL3:
Causal AI: from Data to Action
Dr. Andre Franca , CTO | connectedFlow
In this talk, we will explore and demystify th world of Causal AI for data science practitioners, with a focus on understand cause-and-effect relationships within data to drive optimal decisions. In this talk, we will focus on:
from shapley to DAGs: the dangers of using post-hoc explainability methods as tools for decision making, and how tranditional ML isn't suited in situations where want to perform interventions on the system.
discovering causality: how do we figure out what is causal and what isn't, with a brief introduction to methods of structure learning and causal discovery
optimal decision making: by understanding causality, we now can accurately estimate the impact we can make on our system - how to use this knowledge to derive the best possible actions to make?
This talk is aimed at both data scientists and industry practitioners who have a working knowledge of traditional statistics and basic ML. This talk will also be practical: we will provide you with guidance to immediately start implementing some of these concepts in your daily work.


VIRTUAL4:
Advancing Ethical Natural Language Processing: Towards Culture-Sensitive Language Models
Gopalan Oppiliappan , Head, AI Centre of Excellence | Intel India
Natural Language Processing (NLP) systems play a pivotal role in various applications, from virtual assistants to content generation. However, the potential for biases and insensitivity in language models has raised concerns about equitable representation and cultural understanding. This talk explores the development of Culture-Sensitive Language Models (LLMs) as a progressive step towards addressing these issues. The core principles involve diversifying training data to encompass a wide range of cultures, implementing bias detection and mitigation strategies, and fostering collaboration with cultural experts to enhance contextual understanding.
Our approach emphasizes the importance of ethical guidelines that guide the development and deployment of LLMs, focusing on principles such as avoiding stereotypes, respecting cultural diversity, and handling sensitive topics responsibly. The models are designed to be customizable, allowing users to fine-tune them according to specific cultural requirements, fostering inclusivity and adaptability. The incorporation of multilingual capabilities ensures that the models cater to global linguistic diversity, acknowledging the richness of different languages and cultural expressions.
Moreover, we propose a feedback mechanism where users can report instances of cultural insensitivity, establishing a continuous improvement loop. Transparency and explainability are prioritized to enable users to comprehend the decision-making process of the models, promoting accountability. Through this multidimensional approach, we aim to advance the field of NLP by developing culture-sensitive LLMs that not only understand and respect diverse cultural nuances but also contribute to a more inclusive and ethical use of language technology.



VIRTUAL5:
Advancing Ethical Natural Language Processing: Towards Culture-Sensitive Language Models
Gopalan Oppiliappan , Head, AI Centre of Excellence | Intel India
Natural Language Processing (NLP) systems play a pivotal role in various applications, from virtual assistants to content generation. However, the potential for biases and insensitivity in language models has raised concerns about equitable representation and cultural understanding. This talk explores the development of Culture-Sensitive Language Models (LLMs) as a progressive step towards addressing these issues. The core principles involve diversifying training data to encompass a wide range of cultures, implementing bias detection and mitigation strategies, and fostering collaboration with cultural experts to enhance contextual understanding.
Our approach emphasizes the importance of ethical guidelines that guide the development and deployment of LLMs, focusing on principles such as avoiding stereotypes, respecting cultural diversity, and handling sensitive topics responsibly. The models are designed to be customizable, allowing users to fine-tune them according to specific cultural requirements, fostering inclusivity and adaptability. The incorporation of multilingual capabilities ensures that the models cater to global linguistic diversity, acknowledging the richness of different languages and cultural expressions.
Moreover, we propose a feedback mechanism where users can report instances of cultural insensitivity, establishing a continuous improvement loop. Transparency and explainability are prioritized to enable users to comprehend the decision-making process of the models, promoting accountability. Through this multidimensional approach, we aim to advance the field of NLP by developing culture-sensitive LLMs that not only understand and respect diverse cultural nuances but also contribute to a more inclusive and ethical use of language technology.


VIRTUAL6
Everything About Large Language Models: Pre-training, Fine-tuning, RLHF & State of the Art
Chandra Khatri , VP, Head of AI | Krutrim
Generative Large Language Models like GPT4 have revolutionized the entire tech ecosystem. But what makes them so powerful? What are the secret components which make them generalize to a variety of tasks? In this talk, I will present how these foundation models are trained. What are the steps and core-components behind these LLMs? I will also cover how smaller, domain-specific models can outperform general purpose foundation models like ChatGPT on target use cases


VIRTUAL7:
Machine Learning using PySpark for Text Data Analysis
Bharti Motwani , Clinical Associate Professor | University of Maryland, USA
In this session, unsupervised Machine Learning algorithms like Cluster Analysis and recommendation System and supervised Machine Learning algorithms like Random Forest, Decision Tree, Bagging and Boosting will be discussed for doing analysis using PySpark. The main feature of this workshop will be the implementation of these algorithms using the Text Data. Considering the importance of reviews and text data available on social media platforms, the availability and importance of text data analysis has grown multifold. The session will be particularly helpful for startups and existing business who wanted to use AI for improving performance.


VIRTUAL8:
Everything About Large Language Models: Pre-training, Fine-tuning, RLHF & State of the Art
Chandra Khatri , VP, Head of AI | Krutrim
Generative Large Language Models like GPT4 have revolutionized the entire tech ecosystem. But what makes them so powerful? What are the secret components which make them generalize to a variety of tasks? In this talk, I will present how these foundation models are trained. What are the steps and core-components behind these LLMs? I will also cover how smaller, domain-specific models can outperform general purpose foundation models like ChatGPT on target use cases




# Slide downloads

Great link to all the slides, githubs and things, get them all:

https://docs.google.com/spreadsheets/d/1Xmhh1zfVuWgdyS6O-aKnvVJzDA4RVOvrmzDLoMuWOXM/edit#gid=0

# Videos

They said that all vidoes would be available next week.
Download the videos and get them into my terminal.

