# assimilate_odsc_bootcamp

3 Goals:

1. Reverse Engineer the brain using odsc gain of compute functions.
2. Find someone who can implement LLVM's and ChatGPT and buy them coffee.
3. Get a job doing pure research and demos for replicating whatever ChatGPT is doing in modified domains.  

# Class list, clicky

## Day 1

[class01_data_wrangling_with_python_with_Sheamus_McGovern.md](./class01_data_wrangling_with_python_with_Sheamus_McGovern.md)

[class02_introduction_to_math_for_data_science_by_thomas_nield.md](./class02_introduction_to_math_for_data_science_by_thomas_nield.md)

[class03_practical_introduction_data_viz_for_data_scientists_robert_kosara.md](./class03_practical_introduction_data_viz_for_data_scientists_robert_kosara.md)

[class04_introduction_machine_learning_python_Sudip_Shrestha.md](./class04_introduction_machine_learning_python_Sudip_Shrestha.md)

# Day 2

state of the art open source AI with Hugging face

[class05_state_of_the_art_open_source_ai_hugging_face_julien_simon.md](./class05_state_of_the_art_open_source_ai_hugging_face_julien_simon.md)


[class06_api_for_gpt_andras_zsom.md](./class06_api_for_gpt_andras_zsom.md)

[class07_data_science_biotech_reearch_pharma_eric_ma_phd.md](./class07_data_science_biotech_reearch_pharma_eric_ma_phd.md)


Dive into the lightning ai open source stack and lightning studios to unlock reproducible ai development on the cloud by Luca Antiga.  Lightning AI, CTO.  https://www.linkedin.com/in/lantiga/  Pytorch llightning leading open source framework.


LLM-native products: industry best practices and what's ahead .  By Ivan Lee Datasour.ai CEO/Founder
The next generation of llm powered productions.
vip platinum gold silver bootcamp.



[class08_ben_needs_a_friend_llvm_benjamin_batorsky.md](./class08_ben_needs_a_friend_llvm_benjamin_batorsky.md)



Good:
Machine Learning: Jon k Rohn's https://www.linkedin.com/in/jonkrohn
At Nebula:
https://www.linkedin.com/company/nebula-io
Generative A.I. with Open-Source LLMs: From Training to Deployment with Hugging Face and PyTorch Lightning
Parts of this training will be accessible to anyone who would like to understand how to develop commercially-successful data products in the new paradigm unleashed by LLMs like GPT-4. To make the most of this training, attendees should be proficient in deep learning and Python programming. Jon Krohn's "Deep Learning with PyTorch and TensorFlow" training on April 23rd provides the neural-network foundations for this generative A.I. training.
Tools/Languages utilized: Google Colab and Paperspace, Python
Code can be found in the aptly named code directory (
https://github.com/jonkrohn/NLP-with-LLMs/tree/main/code
Jupyter Notebooks are directly supported for execution in Google Colab
https://colab.research.google.com/
.py files are for running at the command line (see instructions)
N.B.: Code is intended to be accompanied by live instructions and so it will not necessarily be self-explanatory.
https://github.com/jonkrohn/NLP-with-LLMs
https://github.com/jonkrohn/DLTFpT/blob/master/notebooks/softmax_demo.ipynb




Idiomatic Pandas 2pm to 3pm  with matt harrison metasnake.  python and data science corporate trainer consultant.  ODSC East 2024 Prerequisites 100% Prerequisites to download:
1. Install pandas on your machine (using Anaconda or pip).
2. Install Jupyter on your machine.
3. Launch Jupyter and run the following: https://github.com/mattharrison/effective_pandas_book/blob/main/02-install-code.ipynb  
Github: https://github.com/mattharrison/effective_pandas_book
Prerequisites to download:
1. Install pandas on your machine (using Anaconda or pip).
2. Install Jupyter on your machine.
3. Launch Jupyter and run the following: https://github.com/mattharrison/effective_pandas_book/blob/main/02-install-code.ipynb
Github: https://github.com/mattharrison/effective_pandas_book






How to Practice Data-Centric AI and Have AI Improve its Own Dataset (DE Summit) with Jonas Mueller , Chief Scientist and Co-Founder | Cleanlab 
In Machine Learning projects, one starts by exploring the data and training an initial baseline model. While it’s tempting to experiment with different modeling techniques right after that, an emerging science of data-centric AI introduces systematic techniques to utilize the baseline model to find and fix dataset issues. Improving the dataset in this manner, one can drastically improve the initial model’s performance without any change to the modeling code at all! These techniques work with any ML model and the improved dataset can be used to train any type of model (allowing modeling improvements to be stacked on top of dataset improvements). Such automated data curation has been instrumental to the success of AI organizations like OpenAI and Tesla.  
While data scientists have long been improving data through manual labor, data-centric AI studies algorithms to do this automatically. This tutorial will teach you how to operationalize fundamental ideas from data-centric AI across a wide variety of datasets (image, text, tabular, etc). We will cover recent algorithms to automatically identify common issues in real-world data (label errors, bad data annotators, outliers, low-quality examples, and other dataset problems that once identified can be easily addressed to significantly improve trained models). Open-source code to easily run these algorithms within end-to-end Data Science projects will also be demonstrated. After this tutorial, you will know how to use models to improve your data, in order to immediately retrain better models (and iterate this data/model improvement in a virtuous cycle).


### Linear Algebra with John K Rohn is good

* get Assimilate

https://github.com/jonkrohn/DLTFpT/blob/master/notebooks/deep_net_in_pytorch.ipynb


Programming: All code demos will be in Python so experience with it or another object-oriented programming language would be helpful for following along with the code examples.

Mathematics: Familiarity with secondary school-level mathematics will make the class easier to follow along with. If you are comfortable dealing with quantitative information -- such as understanding charts and rearranging simple equations -- then you should be well-prepared to follow along with all of the mathematics.

Github repository for the original Notebook  https://github.com/jonkrohn/ML-foundations/tree/master/notebooks
Linear Algebra Colab 1  https://colab.research.google.com/github/jonkrohn/ML-foundations/blob/master/notebooks/1-intro-to-linear-algebra.ipynb
Linear Algebra Colab 2 https://colab.research.google.com/github/jonkrohn/ML-foundations/blob/master/notebooks/2-linear-algebra-ii.ipynb

Google Drive to Files  https://drive.google.com/drive/folders/1HPiLTf4u-hXJd7ISTHrI28IBls8n4UxG?usp=sharing

Jupyter Notebooks Guide
 https://docs.google.com/document/d/1vpASB2kjn_XUGTJNwknhIEDWfK8cMhq7v8vyoggmw5M/edit#heading=h.wp9t8n7j3og


### Data Cleaning

Clean as You Go: Basic Hygiene in the Modern Data Stack (DE Summit)
Eric Callahan , Principal, Data Solutions | Pickaxe Foundry

When my children walk around the house, they generally leave a trail of mess behind them. They sometimes realize that they shouldn't be doing this, but they’re so excited to move on to the next thing that catches their eye that they’ll say “Oh, I’ll clean it up later.”

As grown adults with wisdom gained from experience, my wife and I know that this means either:

They’ve just signed themselves up for a massive future cleaning job, or … … that someone else will have to clean up after them.

We know that this is not good behavior for a child, so why do we so often do this as Data Engineers?

The culture of “Move Fast and Break Things” has pressured us into closing tickets as quickly as possible, frequently pushing us towards the “Oh, I’ll clean it up later” mindset. While this may save us a few minutes in the short-term, we are creating long term headaches such as:

Piles of small cleanup tasks for later Confusion among peers who try to use incomplete data assets Lack of metadata to activate throughout the Modern Data Stack


### Unlock safety and savings mastering a secure cost effective cloud data lake

Ori Nakar Imperva Principal engineer threat research

Jonathan azaria imperva data science tech lead.




# Slide downloads

Great link to all the slides, githubs and things, get them all:

https://docs.google.com/spreadsheets/d/1Xmhh1zfVuWgdyS6O-aKnvVJzDA4RVOvrmzDLoMuWOXM/edit#gid=0

# Videos

They said that all vidoes would be available next week.
Download the videos and get them into my terminal.

